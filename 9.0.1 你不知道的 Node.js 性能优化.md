# 你不知道的 Node.js 性能优化

## 1、使用最新版本的 Node.js
>最好使用 LTS 版本，长期持续维护


## 2、使用 fast-json-stringify 加速 JSON 序列化

>加速 JSON 序列化,说是比 JSON.stringify 快接近几倍


## 3.有些不赞同, 所以建议  async/await + Promise ,少用 bluebird 

>Promise 是解决回调嵌套地狱的灵丹妙药，特别是当自从 async/await 全面普及之后，
它们的组合无疑成为了 JavaScript 异步编程的终极解决方案，现在大量的项目都已经开始使用这种模式。



- Promise.all() 的并行能力：
```
async function getUserInfo(id) {
    const [profile, repo] = await Promise.all([
        getUserProfile(id),
        getUserRepo(id)
    ])
    return { profile, repo }
}
```


- [fast-async](https://v8.dev/blog/fast-async)


## 5.优化 V8 GC

- 坑一：使用大对象作为缓存，导致老生代（Old Space）的垃圾回收变慢

示例：

```
const cache = {}
async function getUserInfo(id) {
    if (!cache[id]) {
        cache[id] = await getUserInfoFromDatabase(id)
    }
    return cache[id]
}
```

这里我们使用了一个变量 cache 作为缓存，加速用户信息的查询，进行了很多次查询后，  
cache 对象会进入老生代，并且会变得无比庞大，  
而老生代是使用三色标记 + DFS 的方式进行 GC 的，  
一个大对象会直接导致 GC 花费的时间增长（而且也有内存泄漏的风险）。  

解决方法就是：

- 使用 Redis 这样的外部缓存，实际上像 Redis 这样的内存型数据库非常适合这种场景；
- 限制本地缓存对象的大小，比如使用 FIFO、TTL 之类的机制来清理对象中的缓存。


- 坑二：新生代空间不足，导致频繁 GC

这个坑会比较隐蔽。

Node.js 默认给新生代分配的内存是 64MB（64位的机器，后同），  
但因为新生代 GC 使用的是 Scavenge 算法，所以实际能使用的内存只有一半，即 32MB。

解决方法就是，在启动 Node.js 时，修改新生代的内存上限，减少 GC 的次数：

```node --max-semi-space-size=128 app.js```

新生代的内存不是越大越好

随着内存的增大，GC 的次数减少，但每次 GC 所需要的时间也会增加，所以并不是越大越好，

具体数值需要对业务进行压测 profile 才能确定分配多少新生代内存最好。

>但一般根据经验而言，分配 64MB 或者 128MB 是比较合理的。

## 6.使用 pipeline 管理 stream

Node.js v10.0 加入了一个新的特性：stream.pipeline，可以替代 pump 帮助我们更好的管理 stream。

```
const { pipeline } = require('stream');
const fs = require('fs');
const zlib = require('zlib');

pipeline(
    fs.createReadStream('archive.tar'),
    zlib.createGzip(),
    fs.createWriteStream('archive.tar.gz'),
    (err) => {
        if (err) {
            console.error('Pipeline failed', err);
        } else {
            console.log('Pipeline succeeded');
        }
    }
);
```


## 8、使用 node-clinic 快速定位性能问题
- [node-clinic](https://github.com/nearform/node-clinic)

```
npm i -g clinic
npm i -g autocannon
```

使用的时候，先开启服务进程：
```
clinic doctor -- node server.js
```

然后我们可以用任何压测工具跑一次压测，比如使用同一个作者的 autocannon（当然你也可以使用 ab、curl 这样的工具来进行压测。）：

```
autocannon http://localhost:3000
```

压测完毕后，我们 ctrl + c 关闭 clinic 开启的进程，就会自动生成报告,

clinic 也在上面告诉我们检测到了潜在的 I/O 问题

- 使用` clinic bubbleprof `来检测 I/O 问题：
```
clinic bubbleprof -- node server.js
```
再次进行压测后，我们得到了新的报告

- 如何读懂 clinic bubbleprof 生成的报告，可以看这里[Bubbleprof Walkthrough](https://link.juejin.im/?target=http%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fclinicjs.org%2Fbubbleprof%2Fwalkthrough%2F)


- clinic 也可以检测到服务内部的计算性能问题，下面我们做一些“破坏”，让这个服务的性能瓶颈出现在 CPU 计算上。

我们在某个中间件中加入了空转一亿次这样非常消耗 CPU 的“破坏性”代码：

```
function sleep() {
    let n = 0
    while (n++ < 10e7) {
        empty()
    }
}
function empty() { }

module.exports = (ctx, next) => {
    sleep()
    // ......
    return next()
}
```
然后使用 clinic doctor，重复上面的步骤，生成性能报告：

这就是一个非常典型的同步计算阻塞了异步队列的“病例”，即主线程上进行了大量的计算，导致 JavaScript 的异步回调没法及时触发，Event Loop 的延迟极高。

对于这样的应用，我们可以继续使用 clinic flame 来确定到底是哪里出现了密集计算：

```
clinic flame -- node app.js
```
压测后，我们得到了火焰图


## 参考
- [你不知道的Node.js性能优化](https://zhuanlan.zhihu.com/p/50055740)
